{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME=\"b9b30ab6-4a2b-456b-9ffe-64239e097b9c\"\n",
    "PASSWORD=\"w5ficOhxSygH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/McCharChar/Projects/TranscriptionProj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://stream.watsonplatform.net/speech-to-text/api/v1/recognize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-Type': 'audio/mp3'}\n",
    "audio = open(PATH+\"/mc_audio.mp3\", 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, data=audio, headers=headers, auth=(USERNAME, PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          {\n",
      "   \"results\": [\n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.834, \n",
      "               \"transcript\": \"there have been many competing approaches to those challenges one has been a few computers with information the rules about the world which require programmers so Boris the right software as familiar with the attributes of Satan ensure sound that took lots of time and still let the systems unable to deal with ambiguous data they were very limited it to narrow controlled applications such as phone menu systems that ask you to make queries by saying specific words \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.982, \n",
      "               \"transcript\": \"neural networks developed in the nineteen fifties not long after the dawn of a I research on \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.872, \n",
      "               \"transcript\": \"and they look promising because they attempted to simulate the way the brain works though and greatly simplified form \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.648, \n",
      "               \"transcript\": \"a program maps out a set of \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.853, \n",
      "               \"transcript\": \"virtual neurons and then assigns a random numerical values or wait to connections between these weights determine how each simulated neurons responds with a mathematical output between zero and one to a digitized feature such as age or shade of blue and an image or particular energy level adds one frequency of the phone and \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.741, \n",
      "               \"transcript\": \"on the individual unit of sounds and spoken syllables \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.744, \n",
      "               \"transcript\": \"programmers would train and neural network to detect an object or for phone and by blitzing the network with digitized versions of images containing those objects burst out ways \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.611, \n",
      "               \"transcript\": \"containing those phones \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.882, \n",
      "               \"transcript\": \"if the network didn't accurately recognize that particular pattern an algorithm would just wait the eventual goal of this training was to get the network to consistently recognized the pattern feature sets of images that we humans know as say the phone and D. or the image of a dog \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.86, \n",
      "               \"transcript\": \"this is much the same way a child learns what a dog by noticing the detail of had sheep behavior and the \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.665, \n",
      "               \"transcript\": \"and the like and furry barking animals other people call dogs \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.931, \n",
      "               \"transcript\": \"but early neural networks could simulate only a very limited number of neurons at once so they could not recognize patterns of great complexity they languished through the nineteen seventies \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.905, \n",
      "               \"transcript\": \"in the mid nineteen eighties Hinton and others helped spark a revival of interest and neural networks with so called deep models that made better use of many layers of software neurons but the techniques still required heavy human involvement programmers had the label data before feeding it to the network and complex speech or image recognition required more computer power than was available \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.837, \n",
      "               \"transcript\": \"finally however in the last decade Hinton other researchers made some fundamental conceptual breakthroughs in two thousand six Hinton develops up more efficient way to teach individual layers of neurons \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.814, \n",
      "               \"transcript\": \"I'm in the first where learns the primitive features like an edge in an image or the tiniest unit a speech sound \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.93, \n",
      "               \"transcript\": \"it does this by finding combinations of digitized pictures or sound waves that occur more often than they should by chance \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.877, \n",
      "               \"transcript\": \"once that layer accurately recognizes those features they're fed to the next layer which trains itself to recognize more complex features like a corner or a combination of speech sounds \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.708, \n",
      "               \"transcript\": \"the process is repeated and successive layers until the system can reliably recognize phones or objects \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.83, \n",
      "               \"transcript\": \"cats last June Google demonstrated one of the largest neural networks yet \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.849, \n",
      "               \"transcript\": \"with more than a billion connections a team led by Stanford computer science professor Andrew anger and Google fellow Jeff dean show the system images from ten million randomly selected you two videos once simulated neurons in the software model fixated on images of cats \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.806, \n",
      "               \"transcript\": \"others focused on human faces yellow flowers and other objects and thanks to the power of deep learning the system identified these discrete objects even though no humans however defined or label them \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.853, \n",
      "               \"transcript\": \"what's done some a I experts though was the magnitude of improvement in image recognition the system correctly categorize objects and games in the YouTube images sixteen percent of the time and that might not sound impressive but it was \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.745, \n",
      "               \"transcript\": \"as it was seventy percent better than previous previous method \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.826, \n",
      "               \"transcript\": \"in the notes there were twenty two thousand categories to choose from correctly spotting objects into some of them required for example distinguishing between two similar varieties of ski fish I would've been challenging even for most humans \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }, \n",
      "      {\n",
      "         \"alternatives\": [\n",
      "            {\n",
      "               \"confidence\": 0.801, \n",
      "               \"transcript\": \"when the system was asked to sort the images into one thousand more in general categories the accuracy rate jumped above fifty percent \"\n",
      "            }\n",
      "         ], \n",
      "         \"final\": true\n",
      "      }\n",
      "   ], \n",
      "   \"result_index\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e0b83a26e180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alternatives'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transcript'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "r_json['results'][0]['alternatives'][0]['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = \"\"\n",
    "for result in r_json['results']:\n",
    "    tx += result['alternatives'][0]['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there have been many competing approaches to those challenges one has been a few computers with information the rules about the world which require programmers so Boris the right software as familiar with the attributes of Satan ensure sound that took lots of time and still let the systems unable to deal with ambiguous data they were very limited it to narrow controlled applications such as phone menu systems that ask you to make queries by saying specific words neural networks developed in the nineteen fifties not long after the dawn of a I research on and they look promising because they attempted to simulate the way the brain works though and greatly simplified form a program maps out a set of virtual neurons and then assigns a random numerical values or wait to connections between these weights determine how each simulated neurons responds with a mathematical output between zero and one to a digitized feature such as age or shade of blue and an image or particular energy level adds one frequency of the phone and on the individual unit of sounds and spoken syllables programmers would train and neural network to detect an object or for phone and by blitzing the network with digitized versions of images containing those objects burst out ways containing those phones if the network didn't accurately recognize that particular pattern an algorithm would just wait the eventual goal of this training was to get the network to consistently recognized the pattern feature sets of images that we humans know as say the phone and D. or the image of a dog this is much the same way a child learns what a dog by noticing the detail of had sheep behavior and the and the like and furry barking animals other people call dogs but early neural networks could simulate only a very limited number of neurons at once so they could not recognize patterns of great complexity they languished through the nineteen seventies in the mid nineteen eighties Hinton and others helped spark a revival of interest and neural networks with so called deep models that made better use of many layers of software neurons but the techniques still required heavy human involvement programmers had the label data before feeding it to the network and complex speech or image recognition required more computer power than was available finally however in the last decade Hinton other researchers made some fundamental conceptual breakthroughs in two thousand six Hinton develops up more efficient way to teach individual layers of neurons I'm in the first where learns the primitive features like an edge in an image or the tiniest unit a speech sound it does this by finding combinations of digitized pictures or sound waves that occur more often than they should by chance once that layer accurately recognizes those features they're fed to the next layer which trains itself to recognize more complex features like a corner or a combination of speech sounds the process is repeated and successive layers until the system can reliably recognize phones or objects cats last June Google demonstrated one of the largest neural networks yet with more than a billion connections a team led by Stanford computer science professor Andrew anger and Google fellow Jeff dean show the system images from ten million randomly selected you two videos once simulated neurons in the software model fixated on images of cats others focused on human faces yellow flowers and other objects and thanks to the power of deep learning the system identified these discrete objects even though no humans however defined or label them what's done some a I experts though was the magnitude of improvement in image recognition the system correctly categorize objects and games in the YouTube images sixteen percent of the time and that might not sound impressive but it was as it was seventy percent better than previous previous method in the notes there were twenty two thousand categories to choose from correctly spotting objects into some of them required for example distinguishing between two similar varieties of ski fish I would've been challenging even for most humans when the system was asked to sort the images into one thousand more in general categories the accuracy rate jumped above fifty percent \n"
     ]
    }
   ],
   "source": [
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
